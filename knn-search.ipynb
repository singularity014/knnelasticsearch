{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<b>Mount EFS to model dir.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "sudo mount -t nfs \\\n",
    "    -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 \\\n",
    "    fs-xxxxx.efs.ap-southeast-2.amazonaws.com:/ \\\n",
    "    ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo umount -l ./model\n",
    "#!sudo mount -t efs fs-aeced997:/ ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "sudo chmod go+rw ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install sentence-transformers\n",
    "pip install elasticsearch\n",
    "pip install requests_aws4auth\n",
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# wget https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/distilbert-base-nli-mean-tokens.zip\n",
    "# unzip distilbert-base-nli-mean-tokens.zip -d distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sentence_transformers import SentenceTransformer\n",
    "#model = SentenceTransformer('/home/ec2-user/SageMaker/distilbert',device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream task\n",
    "\n",
    "The number of hidden units of Bert is either 768 or 1024, To change the dimension, you must add a dense layer after the pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import models, losses, SentenceTransformer\n",
    "\n",
    "word_embedding_model = models.DistilBERT('distilbert-base-uncased')\n",
    "\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                            pooling_mode_mean_tokens=True,\n",
    "                            pooling_mode_cls_token=False,\n",
    "                            pooling_mode_max_tokens=False)\n",
    "# reduce dim from 768 to 256\n",
    "dense_model = models.Dense(in_features=768, out_features=256)\n",
    "transformer = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Where is the edge of the Universe?']\n",
    "sentence_embeddings = transformer.encode(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Save sentence embedder to mounted EFS directory, hence rest api can use it for embedding.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save(\"model/transformer-v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_transformer =  SentenceTransformer('/home/ec2-user/SageMaker/model/transformer-v1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sentences = ['Where is the edge of the Universe?']\n",
    "_sentence_embeddings = local_transformer.encode(_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _sentence_embeddings[0].tolist() == sentence_embeddings[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "Please be aware of the following requirements about ackonwledgment, copyright and availability, cited from the dataset description page.\n",
    "\n",
    "<blockquote>Question Pairs Dataset on kaggle via @KaggleDatasets https://kaggle.com/quora/question-pairs-dataset?utm_medium=social&utm_campaign=kaggle-dataset-share&utm_source=twitter</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir /home/ec2-user/.kaggle/\n",
    "cp /home/ec2-user/SageMaker/kaggle.json /home/ec2-user/.kaggle/\n",
    "ls /home/ec2-user/.kaggle/\n",
    "chmod 600 /home/ec2-user/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files(\"quora/question-pairs-dataset\", path='quora_dataset', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df = pd.read_csv(\"quora_dataset/questions.csv\", usecols=[\"qid1\", \"question1\"], index_col=False)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_questions_imp = df[:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Creat an index with the index.knn setting and add one or more fields of the knn_vector data type.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "\n",
    "region = 'ap-southeast-2'\n",
    "service = 'es'\n",
    "ssm = boto3.client('ssm', region_name=region)\n",
    "es_parameter = ssm.get_parameter(Name='/KNNSearch/ESUrl')\n",
    "es_host = es_parameter['Parameter']['Value']\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, service, session_token=credentials.token)\n",
    "es = Elasticsearch(\n",
    "    hosts=[{'host': es_host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection\n",
    ")\n",
    "\n",
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 256\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=\"questions\",body=knn_index,ignore=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -X DELETE \"https://vpc-knn-search-infra-es-c6mx5v7cqowwbuus3h5ek2v5kq.ap-southeast-2.es.amazonaws.com/questions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Records Indexing\n",
    "<b>Store the actual data or document.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_import(df):\n",
    "    for index, row in df.iterrows():\n",
    "        vectors = local_transformer.encode([row[\"question1\"]])\n",
    "        print(row[\"question1\"])\n",
    "#         print(vectors[0].tolist())\n",
    "        es.index(index='questions',\n",
    "                 id=row[\"qid1\"], \n",
    "                 body={\"question_vector\": vectors[0].tolist(), \n",
    "                       \"question\": row[\"question1\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_import(df_questions_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Testing knn search from rest api deployed on ECS.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d 'question=How can you fight depression?' http://knn-s-Publi-C8MSNTB6EVFM-207238135.ap-southeast-2.elb.amazonaws.com/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = local_transformer.encode([\"Does the Universe Have an Edge?\"])\n",
    "es.search(index=\"questions\",\n",
    "                    body={\n",
    "                        \"size\": 5,\n",
    "                        \"_source\": {\n",
    "                            \"exclude\": [\"question_vector\"]\n",
    "                        },\n",
    "                        \"min_score\": 0.2,\n",
    "                        \"query\": {\n",
    "                            \"knn\": {\n",
    "                                \"question_vector\": {\n",
    "                                    \"vector\": sentence_embeddings[0].tolist(),\n",
    "                                    \"k\": 5\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Copy sentence embedder to S3 as backup.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp /home/ec2-user/SageMaker/model/transformer-v1/  s3://aiyi.fuzzysearch/transformer-model/ --recursive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
